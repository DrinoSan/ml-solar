{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uBHsHWmumNKn"
   },
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:12:03.922743Z",
     "start_time": "2023-06-01T19:12:03.238947Z"
    },
    "id": "6mXdf5RGkzlk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Company XY introduced solar panels and accompanying batteries to make them self, less dependent on the main grid and therefore reduce their overall energy dependance and CO2 emissions. First phase of the project was successfully completed with installation of solar panels and accompanying batteries. The goal of the second phase is to analyze their consumption and try to reduce the usage of the main grid electricity to zero by using ML for prediction of next possible window where electricity from main grid will be needed. Current analysis has shown that the consumption of energy from main grid is still present and therefore the ML should be deployed to make predictions when the next possible usage from the main grid will take place so that the energy management team can put some measurements in place to prohibit such usage. For example, energy consumption should be reduced during this time to overcome the upcoming need for electricity from main grid.\n",
    "\n",
    "nicht ELWOG  = Consumption from battery\n",
    "Energie-Graz_Lf_ERZ = Consumption from mein Grid\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "rootDir = 'Energiedaten/'\n",
    "\n",
    "# The columns you're interested in\n",
    "columns = ['Energie-Erzeuger', 'Von', 'Bis', 'Kwh']\n",
    "\n",
    "grid_dataframes = []\n",
    "bat_dataframes = []\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        if \"EV_AT0081000801000000000000000307612\" in fname:\n",
    "            df_grid = pd.read_csv(os.path.join(dirName, fname), delimiter=\";\")\n",
    "            new_columns = [\"KA\", \"Energie-Erzeuger\", \"Von\", \"Bis\", \"Kwh\"]\n",
    "\n",
    "            df_grid.columns = new_columns\n",
    "            df_grid = df_grid.reset_index(drop=True)\n",
    "            df_grid = df_grid.drop(\"KA\", axis=1)\n",
    "\n",
    "            df_grid['Kwh'] = df_grid['Kwh'].str.replace(',', '.').astype(float)\n",
    "\n",
    "            df_grid['Von'] = pd.to_datetime(df_grid['Von'], format=\"%d.%m.%Y %H:%M\")\n",
    "            df_grid['Bis'] = pd.to_datetime(df_grid['Bis'], format=\"%d.%m.%Y %H:%M\")\n",
    "\n",
    "            #df_grid.set_index('Von', inplace=True)\n",
    "\n",
    "            grid_data = df_grid[df_grid['Energie-Erzeuger'] == 'Energie-Graz_Lf_ERZ']\n",
    "            grid_dataframes.append(df_grid)\n",
    "        elif \"EV_AT0081000801000000000000000310972\" in fname:\n",
    "            df_bat = pd.read_csv(os.path.join(dirName, fname), delimiter=\";\")\n",
    "\n",
    "            new_columns = [\"KA\", \"Nicht ELWOG\", \"Von\", \"Bis\", \"Kwh\"]\n",
    "\n",
    "            df_bat.columns = new_columns\n",
    "            df_bat = df_bat.reset_index(drop=True)\n",
    "            df_bat = df_bat.drop(\"KA\", axis=1)\n",
    "\n",
    "            df_bat['Kwh'] = df_bat['Kwh'].str.replace(',', '.').astype(float)\n",
    "\n",
    "            df_bat['Von'] = pd.to_datetime(df_bat['Von'], format=\"%d.%m.%Y %H:%M\")\n",
    "            df_bat['Bis'] = pd.to_datetime(df_bat['Bis'], format=\"%d.%m.%Y %H:%M\")\n",
    "            \n",
    "            bat_dataframes.append(df_bat)\n",
    "\n",
    "df_grid = pd.concat(grid_dataframes, ignore_index=True)\n",
    "df_bat = pd.concat(bat_dataframes, ignore_index=True)\n",
    "\n",
    "# Merge the dataframes on 'Von'\n",
    "df = df_bat.merge(df_grid, how='inner', on='Von', suffixes=('_battery', '_grid'))\n",
    "\n",
    "# Select the required columns and rename them\n",
    "df = df[['Von', 'Bis_battery', 'Kwh_battery', 'Kwh_grid']]\n",
    "df.columns = ['von', 'bis', 'battery', 'grid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming main_df is your main DataFrame\n",
    "# Load the holidays data\n",
    "holidays_df = pd.read_csv('Feiertage/holidays.csv')\n",
    "\n",
    "# Convert the 'startDate' and 'endDate' to datetime format\n",
    "holidays_df['startDate'] = pd.to_datetime(holidays_df['startDate'], format='%Y-%m-%d')\n",
    "holidays_df['endDate'] = pd.to_datetime(holidays_df['endDate'], format='%Y-%m-%d')\n",
    "\n",
    "# Initialize a new column 'holiday' in your main DataFrame with 0\n",
    "df['holiday'] = 0\n",
    "\n",
    "# Iterate over the holidays DataFrame\n",
    "for i, row in holidays_df.iterrows():\n",
    "    # Set 'holiday' to 1 where the date is in the holiday date range\n",
    "    df.loc[(df['von'] >= row['startDate']) & (df['von'] <= row['endDate']), 'holiday'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>von</th>\n",
       "      <th>bis</th>\n",
       "      <th>battery</th>\n",
       "      <th>grid</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-01 00:15:00</td>\n",
       "      <td>2022-11-01 00:30:00</td>\n",
       "      <td>1.83000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-01 00:30:00</td>\n",
       "      <td>2022-11-01 00:45:00</td>\n",
       "      <td>1.69125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-01 00:45:00</td>\n",
       "      <td>2022-11-01 01:00:00</td>\n",
       "      <td>1.64375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01 01:00:00</td>\n",
       "      <td>2022-11-01 01:15:00</td>\n",
       "      <td>1.78375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-01 01:15:00</td>\n",
       "      <td>2022-11-01 01:30:00</td>\n",
       "      <td>1.57625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29177</th>\n",
       "      <td>2023-02-28 22:45:00</td>\n",
       "      <td>2023-02-28 23:00:00</td>\n",
       "      <td>1.41125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29178</th>\n",
       "      <td>2023-02-28 23:00:00</td>\n",
       "      <td>2023-02-28 23:15:00</td>\n",
       "      <td>1.39375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>2023-02-28 23:15:00</td>\n",
       "      <td>2023-02-28 23:30:00</td>\n",
       "      <td>1.48250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>2023-02-28 23:30:00</td>\n",
       "      <td>2023-02-28 23:45:00</td>\n",
       "      <td>1.31875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>2023-02-28 23:45:00</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>1.44875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29182 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      von                 bis  battery  grid  holiday\n",
       "0     2022-11-01 00:15:00 2022-11-01 00:30:00  1.83000   0.0        0\n",
       "1     2022-11-01 00:30:00 2022-11-01 00:45:00  1.69125   0.0        0\n",
       "2     2022-11-01 00:45:00 2022-11-01 01:00:00  1.64375   0.0        0\n",
       "3     2022-11-01 01:00:00 2022-11-01 01:15:00  1.78375   0.0        0\n",
       "4     2022-11-01 01:15:00 2022-11-01 01:30:00  1.57625   0.0        0\n",
       "...                   ...                 ...      ...   ...      ...\n",
       "29177 2023-02-28 22:45:00 2023-02-28 23:00:00  1.41125   0.0        0\n",
       "29178 2023-02-28 23:00:00 2023-02-28 23:15:00  1.39375   0.0        0\n",
       "29179 2023-02-28 23:15:00 2023-02-28 23:30:00  1.48250   0.0        0\n",
       "29180 2023-02-28 23:30:00 2023-02-28 23:45:00  1.31875   0.0        0\n",
       "29181 2023-02-28 23:45:00 2023-03-01 00:00:00  1.44875   0.0        0\n",
       "\n",
       "[29182 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bURpf8bkm7-M"
   },
   "source": [
    "## Data Import\n",
    "Import the data from energydata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:32:21.311471Z",
     "start_time": "2023-06-01T19:32:21.235649Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 4 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#df_grid = pd.read_csv(\"Energiedaten/EV_AT0081000801000000000000000307612_Aug_2022.csv\", delimiter=\";\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#df_bat = pd.read_csv(\"Energiedaten/EV_AT0081000801000000000000000310972_Aug_2022.csv\", delimiter=\";\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m#sun_df = pd.read_csv(\"Energiedaten/HISTALP_AT_GRA_SU1_2022_2023-2.csv\", delimiter=\";\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m new_columns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mKA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEnergie-Erzeuger\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVon\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBis\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mKwh\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m df_grid\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m new_columns\n\u001b[1;32m      9\u001b[0m df_grid \u001b[39m=\u001b[39m df_grid\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m df_grid \u001b[39m=\u001b[39m df_grid\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mKA\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 4 elements, new values have 5 elements"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:25:13.856434Z",
     "start_time": "2023-06-01T19:25:13.843425Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m# Define the LSTM model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m---> 44\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m50\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m])))\n\u001b[1;32m     45\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Normalizing the features\n",
    "battery_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "grid_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "df['battery_scaled'] = battery_scaler.fit_transform(np.array(df['battery']).reshape(-1,1))\n",
    "df['grid_scaled'] = grid_scaler.fit_transform(np.array(df['grid']).reshape(-1,1))\n",
    "\n",
    "scaled_data = np.hstack((df['battery_scaled'].values.reshape(-1,1), df['grid_scaled'].values.reshape(-1,1)))\n",
    "\n",
    "\n",
    "# Create sequences of 3 previous time steps (t-2, t-1, t) to predict the next time step (t+1)\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 3\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Reshape y for later compatibility with a keras method\n",
    "y = y[:,1]\n",
    "\n",
    "# Split the data into training (80%) and test sets (20%)\n",
    "# We dont use the train_test_split because we want to preserve the temporal order of the data because -> timeseries\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Transform back to original form\n",
    "train_predict_transformed = grid_scaler.inverse_transform(train_predict)\n",
    "test_predict_transformed = grid_scaler.inverse_transform(test_predict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 21:25:43.514465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-01 21:25:43.516500: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-01 21:25:43.517902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 3, 7), found shape=(1, 7, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[1;32m     41\u001b[0m trainPredict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filerawciu3a.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/codespace/.python/current/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 3, 7), found shape=(1, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Scale your data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['battery', 'grid', 'holiday']])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(len(scaled_data) * 0.80)\n",
    "test_size = len(scaled_data) - train_size\n",
    "train, test = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]\n",
    "\n",
    "# Modify the create_dataset function to include the new holiday column\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])  # Assuming that 'battery' column is what we are predicting\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Number of previous timesteps to use for prediction \n",
    "look_back = 3\n",
    "\n",
    "# Number of features in your input\n",
    "n_features = df.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, n_features)))  # Should be (7, 3)\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "\n",
    "# Invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "Y_train = scaler.inverse_transform([Y_train])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "# Calculate root mean squared error\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "trainScore = np.sqrt(mean_squared_error(Y_train[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(Y_test[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.04 RMSE\n",
      "Test Score: 0.07 RMSE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# calculate root mean squared error\n",
    "train_score = math.sqrt(mean_squared_error(y_train, train_predict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (train_score))\n",
    "\n",
    "test_score = math.sqrt(mean_squared_error(y_test, test_predict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:12:43.114597Z",
     "start_time": "2023-06-01T19:12:43.095179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23341, 3, 3)\n",
      "(5833, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:23:59.627145Z",
     "start_time": "2023-06-01T19:23:59.622932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5525"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Initial decision which Models/Algorithms arr going to br used as potential candidates for the final model. Elaborate why these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T18:23:41.306764Z",
     "start_time": "2023-06-01T18:23:41.304338Z"
    }
   },
   "outputs": [],
   "source": [
    "#LSTM\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Here you should prepare data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:30:45.828656Z",
     "start_time": "2023-06-01T19:30:45.697952Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "grid_data_hourly = grid_data['Kwh'].resample('H').sum()\n",
    "\n",
    "# Reshape data for scaling\n",
    "data = np.array(grid_data_hourly).reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and build Models\n",
    "Use at least two different models. One from deep learning LSTM and one from classical ML (ensemble ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:30:46.540382Z",
     "start_time": "2023-06-01T19:30:46.531286Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(len(scaled_data) * 0.80)\n",
    "test_size = len(scaled_data) - train_size\n",
    "\n",
    "train, test = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 10\n",
    "X_train, Y_train = create_dataset(train, look_back)\n",
    "X_test, Y_test = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:31:23.509772Z",
     "start_time": "2023-06-01T19:30:47.365201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "584/584 - 1s - loss: 0.0164 - 715ms/epoch - 1ms/step\n",
      "Epoch 2/150\n",
      "584/584 - 0s - loss: 0.0149 - 225ms/epoch - 386us/step\n",
      "Epoch 3/150\n",
      "584/584 - 0s - loss: 0.0116 - 217ms/epoch - 372us/step\n",
      "Epoch 4/150\n",
      "584/584 - 0s - loss: 0.0079 - 218ms/epoch - 374us/step\n",
      "Epoch 5/150\n",
      "584/584 - 0s - loss: 0.0058 - 219ms/epoch - 376us/step\n",
      "Epoch 6/150\n",
      "584/584 - 0s - loss: 0.0046 - 220ms/epoch - 376us/step\n",
      "Epoch 7/150\n",
      "584/584 - 0s - loss: 0.0039 - 217ms/epoch - 372us/step\n",
      "Epoch 8/150\n",
      "584/584 - 0s - loss: 0.0035 - 216ms/epoch - 370us/step\n",
      "Epoch 9/150\n",
      "584/584 - 0s - loss: 0.0033 - 218ms/epoch - 374us/step\n",
      "Epoch 10/150\n",
      "584/584 - 0s - loss: 0.0032 - 224ms/epoch - 383us/step\n",
      "Epoch 11/150\n",
      "584/584 - 0s - loss: 0.0030 - 217ms/epoch - 372us/step\n",
      "Epoch 12/150\n",
      "584/584 - 0s - loss: 0.0030 - 218ms/epoch - 373us/step\n",
      "Epoch 13/150\n",
      "584/584 - 0s - loss: 0.0029 - 217ms/epoch - 372us/step\n",
      "Epoch 14/150\n",
      "584/584 - 0s - loss: 0.0028 - 218ms/epoch - 373us/step\n",
      "Epoch 15/150\n",
      "584/584 - 0s - loss: 0.0028 - 217ms/epoch - 372us/step\n",
      "Epoch 16/150\n",
      "584/584 - 0s - loss: 0.0028 - 218ms/epoch - 372us/step\n",
      "Epoch 17/150\n",
      "584/584 - 0s - loss: 0.0027 - 217ms/epoch - 372us/step\n",
      "Epoch 18/150\n",
      "584/584 - 0s - loss: 0.0027 - 218ms/epoch - 372us/step\n",
      "Epoch 19/150\n",
      "584/584 - 0s - loss: 0.0027 - 217ms/epoch - 371us/step\n",
      "Epoch 20/150\n",
      "584/584 - 0s - loss: 0.0027 - 216ms/epoch - 370us/step\n",
      "Epoch 21/150\n",
      "584/584 - 0s - loss: 0.0027 - 215ms/epoch - 369us/step\n",
      "Epoch 22/150\n",
      "584/584 - 0s - loss: 0.0026 - 218ms/epoch - 374us/step\n",
      "Epoch 23/150\n",
      "584/584 - 0s - loss: 0.0026 - 218ms/epoch - 373us/step\n",
      "Epoch 24/150\n",
      "584/584 - 0s - loss: 0.0026 - 216ms/epoch - 370us/step\n",
      "Epoch 25/150\n",
      "584/584 - 0s - loss: 0.0026 - 215ms/epoch - 368us/step\n",
      "Epoch 26/150\n",
      "584/584 - 0s - loss: 0.0026 - 218ms/epoch - 373us/step\n",
      "Epoch 27/150\n",
      "584/584 - 0s - loss: 0.0026 - 218ms/epoch - 373us/step\n",
      "Epoch 28/150\n",
      "584/584 - 0s - loss: 0.0026 - 218ms/epoch - 374us/step\n",
      "Epoch 29/150\n",
      "584/584 - 0s - loss: 0.0025 - 215ms/epoch - 368us/step\n",
      "Epoch 30/150\n",
      "584/584 - 0s - loss: 0.0025 - 215ms/epoch - 368us/step\n",
      "Epoch 31/150\n",
      "584/584 - 0s - loss: 0.0026 - 216ms/epoch - 371us/step\n",
      "Epoch 32/150\n",
      "584/584 - 0s - loss: 0.0025 - 216ms/epoch - 370us/step\n",
      "Epoch 33/150\n",
      "584/584 - 0s - loss: 0.0025 - 220ms/epoch - 376us/step\n",
      "Epoch 34/150\n",
      "584/584 - 0s - loss: 0.0025 - 216ms/epoch - 369us/step\n",
      "Epoch 35/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 371us/step\n",
      "Epoch 36/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 37/150\n",
      "584/584 - 0s - loss: 0.0025 - 219ms/epoch - 375us/step\n",
      "Epoch 38/150\n",
      "584/584 - 0s - loss: 0.0025 - 216ms/epoch - 370us/step\n",
      "Epoch 39/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 372us/step\n",
      "Epoch 40/150\n",
      "584/584 - 0s - loss: 0.0025 - 218ms/epoch - 373us/step\n",
      "Epoch 41/150\n",
      "584/584 - 0s - loss: 0.0025 - 214ms/epoch - 366us/step\n",
      "Epoch 42/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 375us/step\n",
      "Epoch 43/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 44/150\n",
      "584/584 - 0s - loss: 0.0025 - 218ms/epoch - 374us/step\n",
      "Epoch 45/150\n",
      "584/584 - 0s - loss: 0.0025 - 213ms/epoch - 365us/step\n",
      "Epoch 46/150\n",
      "584/584 - 0s - loss: 0.0025 - 213ms/epoch - 364us/step\n",
      "Epoch 47/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 371us/step\n",
      "Epoch 48/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 371us/step\n",
      "Epoch 49/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 372us/step\n",
      "Epoch 50/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 371us/step\n",
      "Epoch 51/150\n",
      "584/584 - 0s - loss: 0.0025 - 219ms/epoch - 375us/step\n",
      "Epoch 52/150\n",
      "584/584 - 0s - loss: 0.0025 - 218ms/epoch - 373us/step\n",
      "Epoch 53/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 54/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 377us/step\n",
      "Epoch 55/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 374us/step\n",
      "Epoch 56/150\n",
      "584/584 - 0s - loss: 0.0025 - 217ms/epoch - 372us/step\n",
      "Epoch 57/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 58/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 59/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 373us/step\n",
      "Epoch 60/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 61/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 375us/step\n",
      "Epoch 62/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 63/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 64/150\n",
      "584/584 - 0s - loss: 0.0025 - 218ms/epoch - 374us/step\n",
      "Epoch 65/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 374us/step\n",
      "Epoch 66/150\n",
      "584/584 - 0s - loss: 0.0025 - 219ms/epoch - 375us/step\n",
      "Epoch 67/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 376us/step\n",
      "Epoch 68/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 378us/step\n",
      "Epoch 69/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 70/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 71/150\n",
      "584/584 - 0s - loss: 0.0024 - 221ms/epoch - 379us/step\n",
      "Epoch 72/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 376us/step\n",
      "Epoch 73/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 376us/step\n",
      "Epoch 74/150\n",
      "584/584 - 0s - loss: 0.0025 - 218ms/epoch - 373us/step\n",
      "Epoch 75/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 76/150\n",
      "584/584 - 0s - loss: 0.0024 - 222ms/epoch - 381us/step\n",
      "Epoch 77/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 376us/step\n",
      "Epoch 78/150\n",
      "584/584 - 0s - loss: 0.0024 - 223ms/epoch - 382us/step\n",
      "Epoch 79/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 80/150\n",
      "584/584 - 0s - loss: 0.0024 - 223ms/epoch - 381us/step\n",
      "Epoch 81/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 376us/step\n",
      "Epoch 82/150\n",
      "584/584 - 0s - loss: 0.0024 - 221ms/epoch - 378us/step\n",
      "Epoch 83/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 369us/step\n",
      "Epoch 84/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 374us/step\n",
      "Epoch 85/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 376us/step\n",
      "Epoch 86/150\n",
      "584/584 - 0s - loss: 0.0024 - 226ms/epoch - 388us/step\n",
      "Epoch 87/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 374us/step\n",
      "Epoch 88/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 375us/step\n",
      "Epoch 89/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 90/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 374us/step\n",
      "Epoch 91/150\n",
      "584/584 - 0s - loss: 0.0024 - 221ms/epoch - 379us/step\n",
      "Epoch 92/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 373us/step\n",
      "Epoch 93/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 94/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 374us/step\n",
      "Epoch 95/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 377us/step\n",
      "Epoch 96/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 97/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 372us/step\n",
      "Epoch 98/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 99/150\n",
      "584/584 - 0s - loss: 0.0023 - 221ms/epoch - 379us/step\n",
      "Epoch 100/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 101/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 370us/step\n",
      "Epoch 102/150\n",
      "584/584 - 0s - loss: 0.0023 - 215ms/epoch - 369us/step\n",
      "Epoch 103/150\n",
      "584/584 - 0s - loss: 0.0024 - 218ms/epoch - 372us/step\n",
      "Epoch 104/150\n",
      "584/584 - 0s - loss: 0.0024 - 220ms/epoch - 376us/step\n",
      "Epoch 105/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 370us/step\n",
      "Epoch 106/150\n",
      "584/584 - 0s - loss: 0.0023 - 215ms/epoch - 368us/step\n",
      "Epoch 107/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 108/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 109/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 110/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 111/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 371us/step\n",
      "Epoch 112/150\n",
      "584/584 - 0s - loss: 0.0024 - 217ms/epoch - 372us/step\n",
      "Epoch 113/150\n",
      "584/584 - 0s - loss: 0.0023 - 221ms/epoch - 378us/step\n",
      "Epoch 114/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 371us/step\n",
      "Epoch 115/150\n",
      "584/584 - 0s - loss: 0.0024 - 219ms/epoch - 375us/step\n",
      "Epoch 116/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 117/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 374us/step\n",
      "Epoch 118/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 372us/step\n",
      "Epoch 119/150\n",
      "584/584 - 0s - loss: 0.0023 - 221ms/epoch - 378us/step\n",
      "Epoch 120/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 121/150\n",
      "584/584 - 0s - loss: 0.0023 - 223ms/epoch - 382us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 372us/step\n",
      "Epoch 123/150\n",
      "584/584 - 0s - loss: 0.0024 - 216ms/epoch - 370us/step\n",
      "Epoch 124/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 370us/step\n",
      "Epoch 125/150\n",
      "584/584 - 0s - loss: 0.0023 - 224ms/epoch - 383us/step\n",
      "Epoch 126/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 374us/step\n",
      "Epoch 127/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 371us/step\n",
      "Epoch 128/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 376us/step\n",
      "Epoch 129/150\n",
      "584/584 - 0s - loss: 0.0023 - 231ms/epoch - 396us/step\n",
      "Epoch 130/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 376us/step\n",
      "Epoch 131/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 372us/step\n",
      "Epoch 132/150\n",
      "584/584 - 0s - loss: 0.0023 - 220ms/epoch - 377us/step\n",
      "Epoch 133/150\n",
      "584/584 - 0s - loss: 0.0023 - 229ms/epoch - 391us/step\n",
      "Epoch 134/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 376us/step\n",
      "Epoch 135/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 371us/step\n",
      "Epoch 136/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 137/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 371us/step\n",
      "Epoch 138/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 375us/step\n",
      "Epoch 139/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 370us/step\n",
      "Epoch 140/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 375us/step\n",
      "Epoch 141/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 373us/step\n",
      "Epoch 142/150\n",
      "584/584 - 0s - loss: 0.0023 - 217ms/epoch - 371us/step\n",
      "Epoch 143/150\n",
      "584/584 - 0s - loss: 0.0023 - 219ms/epoch - 375us/step\n",
      "Epoch 144/150\n",
      "584/584 - 0s - loss: 0.0022 - 219ms/epoch - 375us/step\n",
      "Epoch 145/150\n",
      "584/584 - 0s - loss: 0.0022 - 218ms/epoch - 373us/step\n",
      "Epoch 146/150\n",
      "584/584 - 0s - loss: 0.0023 - 215ms/epoch - 368us/step\n",
      "Epoch 147/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 369us/step\n",
      "Epoch 148/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 370us/step\n",
      "Epoch 149/150\n",
      "584/584 - 0s - loss: 0.0023 - 218ms/epoch - 374us/step\n",
      "Epoch 150/150\n",
      "584/584 - 0s - loss: 0.0023 - 216ms/epoch - 369us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28c80ee50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(20))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation and selection of the model\n",
    "Here multiple models should be evaluated and finaly selected. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T19:31:28.907020Z",
     "start_time": "2023-06-01T19:31:28.626799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 511us/step\n",
      "5/5 [==============================] - 0s 572us/step\n",
      "Train Score: 0.26 RMSE\n",
      "Test Score: 0.44 RMSE\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# invert predictions back to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "Y_train = scaler.inverse_transform([Y_train])\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_score = math.sqrt(mean_squared_error(Y_train[0], train_predict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (train_score))\n",
    "\n",
    "test_score = math.sqrt(mean_squared_error(Y_test[0], test_predict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (test_score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and reflection\n",
    "Please reflect on the project and provide the conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with some data\n",
    "Create your own new data representing wine and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1408671372.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Feiertage/\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pdhf\n",
    "Feiertage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'urlopen' from 'requests' (/home/codespace/.local/lib/python3.10/site-packages/requests/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrequests\u001b[39;00m \u001b[39mimport\u001b[39;00m urlopen\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'urlopen' from 'requests' (/home/codespace/.local/lib/python3.10/site-packages/requests/__init__.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
